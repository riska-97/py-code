# -*- coding: utf-8 -*-
"""Code Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bgwpObFBL0JvX15T6cpGvQbzmghAmIm5

# Lecture 3 (Code Challenge)

Click [here](https://docs.google.com/spreadsheets/d/1wArCQ8-e-crtb1TK9Fek5ZHh0rJpITFgTawF5ixrfU8/edit#gid=0) to see spreadsheet.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

url = 'https://docs.google.com/spreadsheets/d/1wArCQ8-e-crtb1TK9Fek5ZHh0rJpITFgTawF5ixrfU8/edit#gid=0'
url_use = url.replace('edit#','export?format=csv&')
df1 = pd.read_csv(url_use)
df1

df1.isna().sum()

"""Dari hasil code diatas, terlihat bahwa banyak sekali kolom yang null

Lalu, akan di lihat berapa banyak row yang memiliki nilai null dan row yg tidak ada nilai null
"""

df1[df1.isnull().any(axis=1)]

df1[~df1.isnull().any(axis=1)]

"""Dari hasil di atas, terlihat bahwa dari 93 rows yang dimiliki : 73 rows memiliki nilai null dan 20 rows yg tidak ada nilai null.

Oleh karena itu, perlu dipilih kolom yang ingin di gunakan untuk analisa agar tidak terlalu banyak drop data.

Misal, ingin dianalisa mengenai perbandingan Harga Mobil yang dibuat di US dan non-US.

Kolom yang dibutuhkan adalah Manufacturer, Model Mobil, Price dan Origin. Maka akan dibuat dataframe baru yang hanya memuat ke-4 kolom tsb.
"""

df2 = df1[['Manufacturer','Model','Price','Origin']]
df2

df2[df2.isnull().any(axis=1)]

"""Dari hasil di atas, terlihat bahwa >10% rows data masih memiliki nilai null.

Selanjutnya akan di lakukan modifikasi data yaitu menyatukan kolom manufacturer dan Model menjadi 1 kolom baru dan mengisi nilai harga dengan asumsi harga = rata-rata dari Max. Price dan Min. Price.
"""

df1.info()

df1_modif = df1.copy()
df1_modif['Manufacturer'] = df1_modif['Manufacturer'].replace(np.nan,'',regex=True)
df1_modif['Model'] = df1_modif['Model'].replace(np.nan,'',regex=True)
df1_modif['Car_Name'] = df1_modif['Manufacturer'] + ' ' + df1_modif['Model']
df1_modif['Avg_Price'] = df1_modif['Min.Price'] + df1_modif['Max.Price'] / 2
df1_modif['Price'].fillna(df1_modif['Avg_Price'],axis=0,inplace=True)
df1_modif

df2_modif = df1_modif[['Car_Name','Price','Origin']]
df2_modif

df2_modif[df2_modif.isnull().any(axis=1)]

"""Sekarang null yang dimiliki adalah 5% dari data, oleh karena itu akan dilakukan delete row."""

df2_drop = df2_modif.copy()
df2_drop.dropna(axis=0,inplace=True)
df2_drop

#Dilakukan penamaan baru untuk mempermudah melihat step
df3 = df2_drop.copy()
df3['Origin'].value_counts()

"""Setelah di lakukan cleaning null values, di cek apakah terdapat value yang typo.

Hasilnya, pada kolom Origin tidak terdapat value yg typo.

Langkah selanjutnya akan dilihat apakah terdapat data yang duplicate/double.
"""

df3[df3['Car_Name'].duplicated()]

"""Untuk kolom yang di cek adalah kolom Car_Name dan hasilnya tidak terdapat data yang duplicate/double.

Selanjutnya, akan di lihat apakah terdapat outlier pada masing-masing origin.
"""

df3.info()

df3_usa = df3[df3['Origin']=='USA']
df3_usa

df3_nonusa = df3[df3['Origin']=='non-USA']
df3_nonusa

df3_usa.boxplot(column=['Price'],fontsize=10,rot=0,grid=False,figsize=(10,10),vert=False)

df3_nonusa.boxplot(column=['Price'],fontsize=10,rot=0,grid=False,figsize=(10,10),vert=False)

"""Pada boxplot tsb, terlihat bahwa baik pada kategori USA dan non-USA terdapat indikasi adanya outlier."""

#usa
Q1_usa = df3_usa['Price'].quantile(0.25)
Q3_usa = df3_usa['Price'].quantile(0.75)
#non-usa
Q1_nonusa = df3_nonusa['Price'].quantile(0.25)
Q3_nonusa = df3_nonusa['Price'].quantile(0.75)

def box_min (q1,q3) :
  IQR = q3 - q1
  min = q1 - 1.5 * IQR
  return (min)

def box_max (q1,q3) :
  IQR = q3 - q1
  max = q3 + 1.5 * IQR
  return (max)

#usa
df3_usa_filtermin = df3_usa['Price'] < box_min(Q1_usa,Q3_usa)
df3_usa_filtermax = df3_usa['Price'] > box_max(Q1_usa,Q3_usa)
#non-usa
df3_nonusa_filtermin = df3_nonusa['Price'] < box_min(Q1_nonusa,Q3_nonusa)
df3_nonusa_filtermax = df3_nonusa['Price'] > box_max(Q1_nonusa,Q3_nonusa)

df3_usa_clean = df3_usa[~(df3_usa_filtermin|df3_usa_filtermax)]
df3_usa_clean

df3_nonusa_clean = df3_nonusa[~(df3_nonusa_filtermin|df3_nonusa_filtermax)]
df3_nonusa_clean

"""Setelah didapatkan data yang sudah clean, akan di gabungkan menjadi 1 dataframe kembali.

Data sudah dapat digunakan untuk Analisis lebih lanjut.
"""

df4 = pd.concat ([df3_usa_clean,df3_nonusa_clean],axis=0)
df4